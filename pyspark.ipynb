{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1fc70f",
   "metadata": {},
   "source": [
    "# pyspark-demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76dc6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449ab07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DecimalType, IntegerType, StringType, StructType, StructField\n",
    "from pyspark_utils import get_all_rows_joins_unsafe\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('PySpark_Demo')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a5148",
   "metadata": {},
   "source": [
    "**1. Product DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2d78de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----+-------------------------+\n",
      "|id |product_name|price|number_available_in_stock|\n",
      "+---+------------+-----+-------------------------+\n",
      "|1  |Product_1   |10.09|5                        |\n",
      "|2  |Product_2   |50.00|NULL                     |\n",
      "|3  |Product_3   |20.23|0                        |\n",
      "|4  |Product_4   |NULL |NULL                     |\n",
      "|5  |Product_5   |12.40|9                        |\n",
      "|6  |Product_6   |NULL |2                        |\n",
      "+---+------------+-----+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_schema = StructType(fields=[\n",
    "    StructField('id', IntegerType(), False),\n",
    "    StructField('product_name', StringType(), False),\n",
    "    StructField('price', DecimalType(6,2), True),\n",
    "    StructField('number_available_in_stock', IntegerType(), True)\n",
    "])\n",
    "product_csv = os.path.join(\"sample_data\", \"product.csv\")\n",
    "product_df = spark.read.csv(product_csv, schema=product_schema, header=True)\n",
    "product_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6bad5a",
   "metadata": {},
   "source": [
    "**2. Category DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef9ff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+\n",
      "|id |category_name|description     |\n",
      "+---+-------------+----------------+\n",
      "|1  |Category_1   |First category. |\n",
      "|2  |Category_2   |Second category.|\n",
      "|3  |Category_3   |NULL            |\n",
      "|4  |Category_4   |NULL            |\n",
      "+---+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_schema = StructType(fields=[\n",
    "    StructField('id', IntegerType(), False),\n",
    "    StructField('category_name', StringType(), False),\n",
    "    StructField('description', StringType(), True),\n",
    "])\n",
    "category_csv = os.path.join(\"sample_data\", \"category.csv\")\n",
    "category_df = spark.read.csv(category_csv, schema=category_schema, header=True)\n",
    "category_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26348caa",
   "metadata": {},
   "source": [
    "**3. ProductCategory (Joins) DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eb35377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|product_id|category_id|\n",
      "+----------+-----------+\n",
      "|1         |3          |\n",
      "|1         |4          |\n",
      "|2         |3          |\n",
      "|3         |1          |\n",
      "|5         |4          |\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_category_schema = StructType(fields=[\n",
    "    StructField('product_id', IntegerType(), False),\n",
    "    StructField('category_id', IntegerType(), False),\n",
    "])\n",
    "product_category_csv = os.path.join(\"sample_data\", \"product_category.csv\")\n",
    "product_category_df = spark.read.csv(product_category_csv, schema=product_category_schema, header=True)\n",
    "product_category_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd7459",
   "metadata": {},
   "source": [
    "**4. Use fucntion `get_all_rows_joins_unsafe` for get new dataframe with `product_name`, `category_name` columns. You can see the result below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65512ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_all_rows_joins_unsafe:\n",
      "\n",
      " Get all rows according to the given joins between dataframes.\n",
      "\n",
      "    Return:\n",
      "        DataFrame\n",
      "\n",
      "    Note:\n",
      "        The '_unsafe' suffix means that input arguments are not validated and an exception may be thrown.\n",
      "\n",
      "        The `mode` argument specifies the dataframe relative to which the rows will be retrieved.\n",
      "+------------+-------------+\n",
      "|product_name|category_name|\n",
      "+------------+-------------+\n",
      "|   Product_1|   Category_4|\n",
      "|   Product_1|   Category_3|\n",
      "|   Product_2|   Category_3|\n",
      "|   Product_3|   Category_1|\n",
      "|   Product_4|         NULL|\n",
      "|   Product_5|   Category_4|\n",
      "|   Product_6|         NULL|\n",
      "+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('get_all_rows_joins_unsafe:\\n\\n', get_all_rows_joins_unsafe.__doc__.strip())\n",
    "df = get_all_rows_joins_unsafe(\n",
    "    product_df, category_df, product_category_df, \n",
    "    join_df1_pk=\"product_id\", \n",
    "    join_df2_pk=\"category_id\", \n",
    "    columns=(\"product_name\", \"category_name\"),\n",
    "    mode=\"left\"\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc50e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
